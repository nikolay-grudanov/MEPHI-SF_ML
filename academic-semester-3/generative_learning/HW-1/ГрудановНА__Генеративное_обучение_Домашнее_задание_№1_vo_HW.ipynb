{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-KeGw-GCZXk"
      },
      "source": [
        "# Домашнее задание \"Варианционные автоэнкодеры\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Выполнил студент группы  Груданов Николай Алексеевия"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPQ-a1t0gOO_"
      },
      "source": [
        "В этом домашнем задании вам предстоит реализовать VAE для датасета картинок MNIST.\n",
        "\n",
        "Вы научитесь обучать вариационный автоэнкодер (VAE) генерировать новые изображения с нуля. А также сможете управлять генерацией, указывая желаемый класс объекта, и оценивать качество результата с помощью метрики FID.\n",
        "\n",
        "Это домашнее задание состоит из двух частей:\n",
        "\n",
        "* **I часть.** Реализовать безусловную генерацию картинок при помощи VAE тренированную на датасете MNIST и оценить качество по метрике FID.\n",
        "* **II часть.** Реализовать условную генерацию по классу и оценить качество по метрике FID.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2D3ZgfKISwd"
      },
      "source": [
        "Установите библиотеку для подсчета FID:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhYp4gS8ox32",
        "outputId": "497d1893-e552-4c00-be7b-4994b2d8ed70"
      },
      "outputs": [],
      "source": [
        "#!pip install pytorch-fid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch: 2.5.1+rocm6.2\n",
            "ROCm/HIP: 6.2.41133-dd7f95766\n",
            "pytorch-fid: 0.3.0\n",
            "GPU available: True\n",
            "GPU: AMD Radeon RX 7800 XT\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import importlib.metadata\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"ROCm/HIP: {torch.version.hip}\")\n",
        "print(f\"pytorch-fid: {importlib.metadata.version('pytorch-fid')}\")\n",
        "\n",
        "# Проверка доступности GPU\n",
        "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc-Nwikdf1EY"
      },
      "source": [
        "## **I часть. Unconditional VAE (6 баллов)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG1utf_ZoFXj"
      },
      "source": [
        "### Библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CCEPzS2qoHhG"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# Импортните любые необходимые вам библиотеки\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import os\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFU4Gu4vkpf5"
      },
      "source": [
        "### Датасет."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3JalSoZqutl"
      },
      "source": [
        "**Задание**: Скачайте датасет MNIST и подготовьте train dataloader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "A05qEeP6dll1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 3.42MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 248kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 2.01MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.20MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_dataset = datasets.MNIST(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([\n",
        "        transforms.ToTensor(), # [0.0, 1.0] float\n",
        "        transforms.Lambda(lambda x: (x > 0.5).float()) # Binarize\n",
        "        ])\n",
        "    )\n",
        "\n",
        "train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=512,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "test_dataset = datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(), # [0.0, 1.0] float\n",
        "        transforms.Lambda(lambda x: (x > 0.5).float()) # Binarize\n",
        "    ])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3uNroE4L5Y_"
      },
      "source": [
        "**Задание**: Для FID сохраните 10k реальных изображений из MNIST test части в папку"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "urDPJe8DGqGJ"
      },
      "outputs": [],
      "source": [
        "# TODO: Для FID сохраните 10k реальных изображений из MNIST test части в папку\n",
        "\n",
        "os.makedirs('mnist_vae_real', exist_ok=True)\n",
        "\n",
        "for i in range(len(test_dataset)):\n",
        "    img, _ = test_dataset[i]\n",
        "    save_image(img, f'mnist_vae_real/real_{i:05d}.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7HWBHlkq4Du"
      },
      "source": [
        "**Задание**: Визуализируйте 5 рандомных сэмплов из тренировочных данных и 5 сэмплов из тестовых данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "V_ug8vGxCjET",
        "outputId": "830bd59e-6124-4d2d-a61e-ac8e2039f2be"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "\n",
        "for i in range(5):\n",
        "    id = random.randint(0, len(train_dataset) - 1)\n",
        "    img, label = train_dataset[id]\n",
        "    axes[0, i].imshow(img[0], cmap='gray')\n",
        "    axes[0, i].set_title(f'Train Sample {i+1}\\nLabel: {label}')\n",
        "    axes[0, i].axis('off')\n",
        "\n",
        "for i in range(5):\n",
        "    id = random.randint(0, len(test_dataset) - 1)\n",
        "    img, label = test_dataset[id]\n",
        "    axes[1, i].imshow(img[0], cmap='gray')\n",
        "    axes[1, i].set_title(f'Test Sample {i+1}\\nLabel: {label}')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvsYC-qEkrfd"
      },
      "source": [
        "### Модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOE45TA1MHl_"
      },
      "source": [
        "**Задание**: Реализуйте VAE архитектуру"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UOTAmalSGlHY"
      },
      "outputs": [],
      "source": [
        "# TODO: Реализуйте VAE (безусловный)\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim=1, latent_dim=32, hidden_dim=128):\n",
        "        super(VAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # Encoder: изображение -> mu, logvar\n",
        "        # Decoder: z -> изображение\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(input_dim, 32, 4, 2, 1),  # понизим размерность изображения до 14 на 14\n",
        "            nn.ReLU(), # добавляем нелинейность\n",
        "            nn.Conv2d(32, 64, 4, 2, 1), # понизим размерность изображения до 7 на 7\n",
        "            nn.ReLU(), # добавляем нелинейность\n",
        "            nn.Flatten(), # вытягиваем в одномерный вектор\n",
        "            nn.Linear(3136, hidden_dim), # делаем вектор с 128 координатами из вектора с 3136 координатами\n",
        "            nn.ReLU(), # добавляем нелинейность\n",
        "            nn.Linear(hidden_dim, 2 * latent_dim)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dim), # делаем вектор с 128 координатами из вектора с 32 координатами\n",
        "            nn.ReLU(), # добавляем нелинейность\n",
        "            nn.Linear(hidden_dim, 3136), # делаем вектор с 3136 координатами из вектора с 128 координатами\n",
        "            nn.ReLU(), # добавляем нелинейность\n",
        "            nn.Unflatten(1, (64, 7, 7)), # делаем 4D-тензор\n",
        "            nn.ConvTranspose2d(64, 32, 4, 2, 1), # повышаем размерность изображения до 14 на 14\n",
        "            nn.ReLU(), # добавляем нелинейность\n",
        "            nn.ConvTranspose2d(32, input_dim, 4, 2, 1), # повышаем размерность изображения до 28 на 28\n",
        "            nn.Sigmoid() # ф-я активации, которая предсказывает класс пикселя\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = h.chunk(2, dim=-1)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        p_recon = self.decode(z)\n",
        "        return p_recon, mu, logvar, z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P4f4GzioPUz"
      },
      "source": [
        "### Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC5Fg_VXFKa0"
      },
      "source": [
        "**Задание**: Напишите VAE Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HP82mY2Pp7iA"
      },
      "outputs": [],
      "source": [
        "# TODO: Реализуйте функцию потерь VAE (подходит и для CVE)\n",
        "\n",
        "def vae_loss(p_recon, x, mu, logvar):\n",
        "    # Reconstruction loss: BCE (since output is sigmoid)\n",
        "    recon_loss = F.binary_cross_entropy(p_recon, x, reduction='sum')\n",
        "    # KL divergence: D_KL(q(z|x) || p(z))\n",
        "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + kl_loss, recon_loss, kl_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euSht88Hkt4G"
      },
      "source": [
        "### Тренировка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWA7MSUoo4Fv"
      },
      "source": [
        "**Задание**: Обучите модель на датасете MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zaw-ZH4qo5x3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "latent_dim = 32 # MNIST VAEs often use 20–64\n",
        "hidden_dim = 128\n",
        "epochs = 25\n",
        "lr = 1e-3\n",
        "img_size = 28\n",
        "channels = 1\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество доступных GPU: 1\n",
            "Имя текущего GPU: AMD Radeon RX 7800 XT\n",
            "Индекс текущего GPU: 0\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(f\"Количество доступных GPU: {torch.cuda.device_count()}\")\n",
        "    print(f\"Имя текущего GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Индекс текущего GPU: {torch.cuda.current_device()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lDJp84sMp_fe"
      },
      "outputs": [],
      "source": [
        "# TODO: Обучите модель\n",
        "\n",
        "def train_vae(model, train_loader, epochs=1000):\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  train_losses = []\n",
        "  recon_losses = []\n",
        "  kl_losses = []\n",
        "  best_loss = 1e38\n",
        "  best_model_state = None\n",
        "\n",
        "  model.train()\n",
        "  for epoch in range(epochs):\n",
        "      total_loss = 0\n",
        "      total_recon = 0\n",
        "      total_kl = 0\n",
        "      num_batches = 0\n",
        "\n",
        "      for i, batch in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')):\n",
        "          x = batch[0].to(device)\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          p_recon, mu, logvar, z = model(x)\n",
        "          loss, recon_loss, kl_loss = vae_loss(p_recon, x, mu, logvar)\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          total_loss += loss.item()\n",
        "          total_recon += recon_loss.item()\n",
        "          total_kl += kl_loss.item()\n",
        "          num_batches += 1\n",
        "\n",
        "      avg_loss = total_loss / len(train_loader.dataset)\n",
        "      avg_recon = total_recon / len(train_loader.dataset)\n",
        "      avg_kl = total_kl / len(train_loader.dataset)\n",
        "\n",
        "      train_losses.append(avg_loss)\n",
        "      recon_losses.append(avg_recon)\n",
        "      kl_losses.append(avg_kl)\n",
        "\n",
        "      print(f'На эпохе {epoch+1} Loss : {round(avg_loss, 4)}, Recon : {round(avg_recon, 4)}, KL : {round(avg_kl, 4)}')\n",
        "\n",
        "      if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            best_model_state = model.state_dict().copy()\n",
        "\n",
        "  print(f'\\nЛучший Loss: {round(best_loss, 4)}')\n",
        "  model.load_state_dict(best_model_state)\n",
        "\n",
        "  return train_losses, recon_losses, kl_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08S2QyZbNkFp",
        "outputId": "ea2d6089-ac5e-4ab1-a6a9-3330dce9e30b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/25:   0%|          | 0/118 [00:00<?, ?it/s]/home/gna/anaconda3/envs/rocm/lib/python3.10/site-packages/torch/nn/modules/linear.py:125: UserWarning: Attempting to use hipBLASLt on an unsupported architecture! Overriding blas backend to hipblas (Triggered internally at ../aten/src/ATen/Context.cpp:296.)\n",
            "  return F.linear(input, self.weight, self.bias)\n",
            "Epoch 1/25: 100%|██████████| 118/118 [00:08<00:00, 14.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 1 Loss : 236.0776, Recon : 232.3195, KL : 3.7581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/25: 100%|██████████| 118/118 [00:04<00:00, 23.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 2 Loss : 191.3035, Recon : 186.3689, KL : 4.9346\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/25: 100%|██████████| 118/118 [00:05<00:00, 23.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 3 Loss : 155.9733, Recon : 142.7683, KL : 13.2049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/25: 100%|██████████| 118/118 [00:05<00:00, 22.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 4 Loss : 128.9101, Recon : 109.6609, KL : 19.2492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/25: 100%|██████████| 118/118 [00:05<00:00, 22.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 5 Loss : 114.0083, Recon : 91.8651, KL : 22.1432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/25: 100%|██████████| 118/118 [00:05<00:00, 22.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 6 Loss : 105.5479, Recon : 82.277, KL : 23.2709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/25: 100%|██████████| 118/118 [00:05<00:00, 21.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 7 Loss : 99.5292, Recon : 75.594, KL : 23.9352\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/25: 100%|██████████| 118/118 [00:05<00:00, 22.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 8 Loss : 95.5719, Recon : 71.2002, KL : 24.3717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/25: 100%|██████████| 118/118 [00:04<00:00, 23.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 9 Loss : 92.535, Recon : 67.8986, KL : 24.6364\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/25: 100%|██████████| 118/118 [00:04<00:00, 23.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 10 Loss : 90.0241, Recon : 65.1682, KL : 24.856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/25: 100%|██████████| 118/118 [00:05<00:00, 23.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 11 Loss : 87.9537, Recon : 62.9205, KL : 25.0332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/25: 100%|██████████| 118/118 [00:05<00:00, 23.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 12 Loss : 86.5738, Recon : 61.3565, KL : 25.2173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/25: 100%|██████████| 118/118 [00:05<00:00, 22.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 13 Loss : 85.2449, Recon : 59.8227, KL : 25.4222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/25: 100%|██████████| 118/118 [00:05<00:00, 22.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 14 Loss : 84.2898, Recon : 58.6502, KL : 25.6396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/25: 100%|██████████| 118/118 [00:04<00:00, 23.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 15 Loss : 83.5101, Recon : 57.7051, KL : 25.805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/25: 100%|██████████| 118/118 [00:05<00:00, 23.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 16 Loss : 82.8389, Recon : 56.8761, KL : 25.9628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/25: 100%|██████████| 118/118 [00:05<00:00, 23.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 17 Loss : 82.0628, Recon : 55.946, KL : 26.1168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/25: 100%|██████████| 118/118 [00:05<00:00, 23.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 18 Loss : 81.5655, Recon : 55.3799, KL : 26.1856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/25: 100%|██████████| 118/118 [00:05<00:00, 23.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 19 Loss : 81.0714, Recon : 54.7479, KL : 26.3235\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/25: 100%|██████████| 118/118 [00:05<00:00, 23.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 20 Loss : 80.641, Recon : 54.2431, KL : 26.3979\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/25: 100%|██████████| 118/118 [00:05<00:00, 23.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 21 Loss : 80.1376, Recon : 53.6647, KL : 26.4729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/25: 100%|██████████| 118/118 [00:04<00:00, 24.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 22 Loss : 79.8635, Recon : 53.301, KL : 26.5625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/25: 100%|██████████| 118/118 [00:04<00:00, 23.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 23 Loss : 79.5027, Recon : 52.9008, KL : 26.6018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/25: 100%|██████████| 118/118 [00:05<00:00, 23.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 24 Loss : 79.2937, Recon : 52.6283, KL : 26.6654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/25: 100%|██████████| 118/118 [00:05<00:00, 23.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 25 Loss : 78.9791, Recon : 52.2351, KL : 26.7441\n",
            "\n",
            "Лучший Loss: 78.9791\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "vae_model = VAE(input_dim=channels, latent_dim=latent_dim, hidden_dim=hidden_dim).to(device)\n",
        "vae_train_losses, vae_recon_losses, vae_kl_losses = train_vae(vae_model, train_loader, epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqKZRnxnk2ON"
      },
      "source": [
        "### Метрика"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm1SCUUjk42O"
      },
      "source": [
        "В этом разделе вам необходимо посчитать метрику FID."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Weiu7gOmk_TW"
      },
      "source": [
        "**Что такое FID?**\n",
        "\n",
        "**FID (Fréchet Inception Distance)** — это метрика качества генеративных моделей для изображений, которая измеряет **расстояние между распределениями признаков реальных и сгенерированных изображений** в пространстве предобученной нейросети (обычно Inception-v3).\n",
        "\n",
        "Чем **ниже FID**, тем **ближе** сгенерированные изображения к реальным — как по **качеству**, так и по **разнообразию**.\n",
        "\n",
        "Формула FID основана на предположении, что признаки в этом пространстве приблизительно распределены как **многомерное нормальное распределение**:\n",
        "\n",
        "$$\n",
        "\\text{FID} = \\|\\mu_r - \\mu_g\\|^2 + \\mathrm{Tr}\\left( \\Sigma_r + \\Sigma_g - 2\\sqrt{\\Sigma_r \\Sigma_g} \\right)\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $(\\mu_r, \\Sigma_r)$ — среднее и ковариационная матрица признаков **реальных** изображений,\n",
        "- $(\\mu_g, \\Sigma_g)$ — то же для **сгенерированных** изображений,\n",
        "- $\\mathrm{Tr}(\\cdot)$ — след матрицы.\n",
        "\n",
        "> 🔹 FID = 0 означает полное совпадение распределений.  \n",
        "> 🔹 Чем выше FID ↑ , тем качество или разнообразие генерации ниже ↓."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKKlXLdNlCGZ"
      },
      "source": [
        "**Как считать FID на MNIST?**\n",
        "\n",
        "Вычислите FID с помощью библиотеки [`pytorch-fid`](https://github.com/mseitzer/pytorch-fid):\n",
        "\n",
        "```bash\n",
        "python -m pytorch_fid real_mnist/ fake_mnist/ --device cuda\n",
        "```\n",
        "\n",
        "> **Важно**: несмотря на то, что признаки Inception-v3 не оптимальны для рукописных цифр, FID остаётся полезной **относительной метрикой** — она позволяет сравнивать разные модели между собой при одинаковых условиях предобработки.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI93gAkQEg7O"
      },
      "source": [
        "**Задание:** Сгенерируйте и сохраните 10 тыс. изображений, выберите 10 тыс. реальных изображений из MNIST тестовой выборки и посчитайте FID между реальными и сгенерированными изображениями."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxAwIJq4zb7A",
        "outputId": "f0108632-5c6d-472f-a949-5a2537645a00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Закончил\n"
          ]
        }
      ],
      "source": [
        "# TODO: Сгенерируйте и сохраните 10 тыс. изображений для FID в папке mnist_vae_fake\n",
        "\n",
        "vae_samles = 10000\n",
        "os.makedirs('mnist_vae_fake', exist_ok=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.randn(vae_samles, vae_model.latent_dim).to(device)\n",
        "    vae_fake_images = vae_model.decode(z)\n",
        "    vae_fake_binary = (vae_fake_images > 0.5).float()\n",
        "    for i in range(vae_samles):\n",
        "        save_image(vae_fake_binary[i], f'mnist_vae_fake/mnist_vae_fake_{i:05d}.png')\n",
        "\n",
        "    print('Закончил')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzL3USg_riUK",
        "outputId": "c56b0a81-192b-406e-af6c-43a25145fbd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /home/gna/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n",
            "100%|██████████████████████████████████████| 91.2M/91.2M [00:18<00:00, 5.21MB/s]\n",
            "100%|█████████████████████████████████████████| 200/200 [00:29<00:00,  6.83it/s]\n",
            "100%|█████████████████████████████████████████| 200/200 [00:11<00:00, 17.02it/s]\n",
            "FID:  6.8374604032847515\n"
          ]
        }
      ],
      "source": [
        "# Чтобы вычислить FID, запустите в терминале:\n",
        "# !pip install pytorch-fid\n",
        "!python -m pytorch_fid mnist_vae_real mnist_vae_fake --device cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw-YrISFHgnu"
      },
      "source": [
        "## **II Часть. Conditional VAE (6 баллов)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVMf6pBnHd8b"
      },
      "source": [
        "Мы уже научились обучать обычный VAE на датасете картинок и получать новые картинки. Давайте теперь научимся обучать модель, которая сможет генерировать не просто рандомную картинку, которая похожа на картинки из датасета, а картинку из конкретного класса. Например, в MNIST датасете 10 классов (от 1 до 10) и мы хотим говорить модели \"Сгенерируй мне только конкретно картинку с числом 3.\" и она должна теперь уже сгенерировать только картинку с числом 3. Как раз Conditional VAE это должен уметь делать и генерировать картинку, обуславливаясь на конкретный класс.\n",
        "\n",
        "\n",
        "**Задание**. В этой части домашнего задания вам предстоит обучить Conditional VAE на MNIST. Это значит, что модель на вход должна принимать картинку и класс картинки.\n",
        "\n",
        "**Метрика**. Вам нужно сгенерировать 1000 сэмплов на каждый класс и посчитать FID для каждого класса."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "YWFKXSxOJtwS"
      },
      "outputs": [],
      "source": [
        "# TODO: Реализуйте Condiional VAE — добавьте one-hot класс как вход в encoder и decoder\n",
        "\n",
        "class CVAE(nn.Module):\n",
        "    def __init__(self, input_dim=1, latent_dim=32, hidden_dim=128, num_classes=10):\n",
        "        super(CVAE, self).__init__()\n",
        "        # TODO\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "        # Архитектура как в VAE\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(input_dim + num_classes, 32, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3136, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 2 * latent_dim)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim + num_classes, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 3136),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (64, 7, 7)),\n",
        "            nn.ConvTranspose2d(64, 32, 4, 2, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, input_dim, 4, 2, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x, c):\n",
        "        # TODO: конкатенируйте x и c по каналам\n",
        "        c = c.view(c.size(0), c.size(1), 1, 1).expand(-1, -1, x.size(2), x.size(3))\n",
        "        x = torch.cat([x, c], dim=1)\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = h.chunk(2, dim=-1)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z, c):\n",
        "        # TODO: конкатенируйте z и c\n",
        "        z = torch.cat([z, c], dim=1)\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x, c):\n",
        "        # TODO\n",
        "        mu, logvar = self.encode(x, c)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        p_recon = self.decode(z, c)\n",
        "        return p_recon, mu, logvar, z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "x5KuxfgDtPCi"
      },
      "outputs": [],
      "source": [
        "# TODO: Обучите CVAE\n",
        "\n",
        "def train_cvae(model, train_loader, epochs=1000):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    train_losses = []\n",
        "    recon_losses = []\n",
        "    kl_losses = []\n",
        "    best_loss = 1e38\n",
        "    best_model_state = None\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        total_recon = 0\n",
        "        total_kl = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        for i, batch in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')):\n",
        "            x = batch[0].to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            p_recon, mu, logvar, z = model(x, F.one_hot(batch[1], model.num_classes).float().to(device))\n",
        "            loss, recon_loss, kl_loss = vae_loss(p_recon, x, mu, logvar) # для CVAE ф-я потерь точно такая же, как и для VAE\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_recon += recon_loss.item()\n",
        "            total_kl += kl_loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader.dataset)\n",
        "        avg_recon = total_recon / len(train_loader.dataset)\n",
        "        avg_kl = total_kl / len(train_loader.dataset)\n",
        "\n",
        "        train_losses.append(avg_loss)\n",
        "        recon_losses.append(avg_recon)\n",
        "        kl_losses.append(avg_kl)\n",
        "\n",
        "        print(f'На эпохе {epoch+1} Loss : {round(avg_loss, 4)}, Recon : {round(avg_recon, 4)}, KL : {round(avg_kl, 4)}')\n",
        "\n",
        "        if avg_loss < best_loss:\n",
        "              best_loss = avg_loss\n",
        "              best_model_state = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    print(f'\\nЛучший Loss: {round(best_loss, 4)}')\n",
        "    model.load_state_dict(best_model_state)\n",
        "\n",
        "    return train_losses, recon_losses, kl_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njiup5m3bvIk",
        "outputId": "fc4fb52e-b21e-4ae3-c3cc-02cdb001df95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/25:  97%|█████████▋| 115/118 [00:05<00:00, 24.00it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/25: 100%|██████████| 118/118 [00:05<00:00, 20.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 1 Loss : 233.3465, Recon : 230.5637, KL : 2.7827\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/25: 100%|██████████| 118/118 [00:05<00:00, 23.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 2 Loss : 168.7422, Recon : 161.1697, KL : 7.5725\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/25: 100%|██████████| 118/118 [00:05<00:00, 22.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 3 Loss : 130.4595, Recon : 115.0116, KL : 15.4479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/25: 100%|██████████| 118/118 [00:05<00:00, 23.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 4 Loss : 111.8914, Recon : 93.3032, KL : 18.5882\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/25: 100%|██████████| 118/118 [00:04<00:00, 23.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 5 Loss : 101.053, Recon : 80.897, KL : 20.156\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/25: 100%|██████████| 118/118 [00:04<00:00, 23.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 6 Loss : 94.4905, Recon : 73.5083, KL : 20.9823\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/25: 100%|██████████| 118/118 [00:04<00:00, 24.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 7 Loss : 89.99, Recon : 68.4509, KL : 21.5391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/25: 100%|██████████| 118/118 [00:05<00:00, 22.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 8 Loss : 86.8644, Recon : 64.8858, KL : 21.9786\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/25: 100%|██████████| 118/118 [00:05<00:00, 23.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 9 Loss : 84.5846, Recon : 62.2903, KL : 22.2942\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/25: 100%|██████████| 118/118 [00:04<00:00, 23.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 10 Loss : 82.9981, Recon : 60.4765, KL : 22.5215\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/25: 100%|██████████| 118/118 [00:04<00:00, 23.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 11 Loss : 81.7374, Recon : 59.0879, KL : 22.6495\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/25: 100%|██████████| 118/118 [00:05<00:00, 23.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 12 Loss : 80.5551, Recon : 57.7261, KL : 22.829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/25: 100%|██████████| 118/118 [00:04<00:00, 23.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 13 Loss : 79.5174, Recon : 56.5458, KL : 22.9715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/25: 100%|██████████| 118/118 [00:05<00:00, 23.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 14 Loss : 78.8995, Recon : 55.8178, KL : 23.0817\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/25: 100%|██████████| 118/118 [00:04<00:00, 23.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 15 Loss : 78.3094, Recon : 55.1672, KL : 23.1422\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/25: 100%|██████████| 118/118 [00:05<00:00, 23.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 16 Loss : 77.7473, Recon : 54.5709, KL : 23.1765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/25: 100%|██████████| 118/118 [00:05<00:00, 20.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 17 Loss : 77.1809, Recon : 53.9188, KL : 23.2621\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/25: 100%|██████████| 118/118 [00:06<00:00, 16.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 18 Loss : 76.563, Recon : 53.1754, KL : 23.3876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/25: 100%|██████████| 118/118 [00:06<00:00, 17.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 19 Loss : 76.2268, Recon : 52.8229, KL : 23.4039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/25: 100%|██████████| 118/118 [00:06<00:00, 18.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 20 Loss : 75.8991, Recon : 52.4942, KL : 23.4048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/25: 100%|██████████| 118/118 [00:06<00:00, 18.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 21 Loss : 75.4919, Recon : 52.0336, KL : 23.4583\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/25: 100%|██████████| 118/118 [00:06<00:00, 17.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 22 Loss : 75.0212, Recon : 51.4658, KL : 23.5554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/25: 100%|██████████| 118/118 [00:06<00:00, 19.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 23 Loss : 74.8623, Recon : 51.3073, KL : 23.555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/25: 100%|██████████| 118/118 [00:05<00:00, 19.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 24 Loss : 74.5763, Recon : 50.9809, KL : 23.5954\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/25: 100%|██████████| 118/118 [00:05<00:00, 19.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "На эпохе 25 Loss : 74.3196, Recon : 50.665, KL : 23.6546\n",
            "\n",
            "Лучший Loss: 74.3196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "num_classes = 10\n",
        "cvae_model = CVAE(input_dim=channels, latent_dim=latent_dim, hidden_dim=hidden_dim, num_classes=num_classes).to(device)\n",
        "cvae_train_losses, cvae_recon_losses, cvae_kl_losses = train_cvae(cvae_model, train_loader, epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STtYG45mYOw8",
        "outputId": "59a8a5ff-cc2e-4490-88c6-1d393488333b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Закончил\n"
          ]
        }
      ],
      "source": [
        "# TODO: Сгенерируйте 1000 сэмплов для каждого класса при помощи CVAE модели\n",
        "\n",
        "cvae_samles = 1000\n",
        "cvae_model.eval()\n",
        "\n",
        "os.makedirs('fake_per_class', exist_ok=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(num_classes):\n",
        "        class_dir = f'fake_per_class/class_{i}'\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "        cvae_fake_images = cvae_model.decode(torch.randn(cvae_samles, cvae_model.latent_dim).to(device), torch.eye(num_classes).to(device)[[i]*cvae_samles])\n",
        "        cvae_fake_binary = (cvae_fake_images > 0.5).float()\n",
        "\n",
        "        for j in range(cvae_fake_binary.shape[0]):\n",
        "            save_image(cvae_fake_binary[j], f'{class_dir}/fake_{j:05d}.png')\n",
        "\n",
        "    print('Закончил')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS0dfUCsJ4o_",
        "outputId": "65fe39e7-0b65-426e-9470-75f524bb3059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Закончил\n"
          ]
        }
      ],
      "source": [
        "# TODO: Сохраните 1000 сэмплов для каждого класса из реального датасета MNIST тестовой части\n",
        "\n",
        "real_mnist_samples = 1000\n",
        "os.makedirs('real_per_class', exist_ok=True)\n",
        "\n",
        "class_dict = {i: [] for i in range(10)}\n",
        "for i, (_, label) in enumerate(test_dataset):\n",
        "    if len(class_dict[label]) < real_mnist_samples:\n",
        "        class_dict[label].append(i)\n",
        "\n",
        "for i, id in class_dict.items():\n",
        "    class_dir = f'real_per_class/class_{i}'\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "    for i, j in enumerate(id):\n",
        "        img, _ = test_dataset[j]\n",
        "        save_image(img, f'{class_dir}/real_{i:05d}.png')\n",
        "\n",
        "print('Закончил')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Voii0NlN7i8t",
        "outputId": "ef5cef8e-04da-4f4e-c8aa-c666fb9ff24d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class 0\n",
            "100%|███████████████████████████████████████████| 20/20 [00:11<00:00,  1.70it/s]\n",
            "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 14.83it/s]\n",
            "FID:  8.939947363274612\n",
            "\n",
            "Class 1\n",
            "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 14.23it/s]\n",
            "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 14.77it/s]\n",
            "FID:  15.883998862323466\n",
            "\n",
            "Class 2\n",
            "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 14.13it/s]\n",
            "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 15.04it/s]\n",
            "FID:  12.23198978662144\n",
            "\n",
            "Class 3\n",
            "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 14.38it/s]\n",
            "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 15.45it/s]\n",
            "FID:  6.867481544665679\n",
            "\n",
            "Class 4\n",
            "100%|███████████████████████████████████████████| 20/20 [00:12<00:00,  1.61it/s]\n",
            "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 14.57it/s]\n",
            "FID:  10.520334874655006\n",
            "\n",
            "Class 5\n",
            "100%|███████████████████████████████████████████| 18/18 [00:15<00:00,  1.16it/s]\n",
            "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 15.16it/s]\n",
            "FID:  9.857338903322244\n",
            "\n",
            "Class 6\n",
            "100%|███████████████████████████████████████████| 20/20 [00:04<00:00,  4.73it/s]\n",
            "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 15.27it/s]\n",
            "FID:  9.800318578674137\n",
            "\n",
            "Class 7\n",
            "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 14.34it/s]\n",
            "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 15.50it/s]\n",
            "FID:  11.679675315961873\n",
            "\n",
            "Class 8\n",
            "100%|███████████████████████████████████████████| 20/20 [00:09<00:00,  2.11it/s]\n",
            "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 15.35it/s]\n",
            "FID:  9.08791154284583\n",
            "\n",
            "Class 9\n",
            "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 14.40it/s]\n",
            "100%|███████████████████████████████████████████| 20/20 [00:01<00:00, 15.51it/s]\n",
            "FID:  7.6398798215632695\n"
          ]
        }
      ],
      "source": [
        "# TODO: Посчитайте FID для каждого класса между сгенерированными и реальными изображениями\n",
        "# Example:\n",
        "#print(\"Class 0\")\n",
        "#!python -m pytorch_fid real_per_class/class_0 fake_per_class/class_0 --device cuda\n",
        "\n",
        "for i in range(num_classes):\n",
        "    print(f\"\\nClass {i}\")\n",
        "    real_dir = f'real_per_class/class_{i}'\n",
        "    fake_dir = f'fake_per_class/class_{i}'\n",
        "    !python -m pytorch_fid {real_dir} {fake_dir} --device cuda"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rocm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
