{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fec591c2-1970-4d42-b294-9c69d1fd8370",
      "metadata": {
        "id": "fec591c2-1970-4d42-b294-9c69d1fd8370"
      },
      "source": [
        "# Сессионное задание: Диффузионные модели"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "630e8b26-0b49-4d86-9c6d-97ba1cb1b4bd",
      "metadata": {
        "id": "630e8b26-0b49-4d86-9c6d-97ba1cb1b4bd"
      },
      "source": [
        "**План задания** (суммарно **50 баллов**)\n",
        "\n",
        "1. **2D-датасет SwissRoll** (суммарно **40 баллов**)\n",
        "    1. Реализовать прямой и обратный процессы диффузии и обучить базовый DDPM. (20 баллов)\n",
        "    2. Реализовать classifier-free guidance. (10 баллов)\n",
        "    3. Реализовать ускоренный семплинг. (10 баллов)\n",
        "\n",
        "2. **Датасет MNIST** (суммарно **10 баллов**)\n",
        "    1. Визуализировать прямой диффузионный процесс. (1 балл)\n",
        "    2. Обучить диффузионную модель с визуально хорошим качеством генерации. (7 баллов)\n",
        "    3. Сравнить генерации с помощью classifier-free guidance для разных значений guidance scale. (2 балла)\n",
        "\n",
        "Ваша задача — заполнить пропуски внутри блоков с подписью `ваш код`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если вы работаете в `Google Colab`, нужно, чтобы Python «видел» дополнительный файл `utils.py`, который приложен к заданию:\n",
        "\n",
        "1. Загрузите файл `utils.py` на ваш Google Drive.\n",
        "2. Раскомментируйте код ниже.\n",
        "3. Укажите в переменной `path` путь к файлу `utils.py` на вашем Google Drive.\n"
      ],
      "metadata": {
        "id": "wC3BdFB0X5_f"
      },
      "id": "wC3BdFB0X5_f"
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# path = \"drive/MyDrive/Teaching/2025-generative-model-miphi/Домашки/3_diffusion/utils.py\"\n",
        "# !cp $path ."
      ],
      "metadata": {
        "id": "Q92b2un4X74v"
      },
      "id": "Q92b2un4X74v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70a85d0d-c381-4b30-8dea-22ab76bc7b70",
      "metadata": {
        "id": "70a85d0d-c381-4b30-8dea-22ab76bc7b70"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_swiss_roll\n",
        "from sklearn.utils import shuffle\n",
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "from typing import Optional, Tuple, List\n",
        "\n",
        "from utils import get_labeled_data_loader, MyUNet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d34fcac2-f605-43ec-b740-427150fd4ed6",
      "metadata": {
        "id": "d34fcac2-f605-43ec-b740-427150fd4ed6"
      },
      "source": [
        "## DDPM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05f71320-b6b6-451e-9625-a823fa68a0f3",
      "metadata": {
        "id": "05f71320-b6b6-451e-9625-a823fa68a0f3"
      },
      "source": [
        "В этой части мы реализуем свою собственную модель (DDPM) и применим её на датасете SwissRoll."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ca8ebc9-fb36-4d25-b737-58758aae9bb7",
      "metadata": {
        "id": "0ca8ebc9-fb36-4d25-b737-58758aae9bb7"
      },
      "outputs": [],
      "source": [
        "def make_swiss_dataset(num_samples):\n",
        "    X0, _ = make_swiss_roll(num_samples // 2, noise=0.3, random_state=0)\n",
        "    X1, _ = make_swiss_roll(num_samples // 2, noise=0.3, random_state=0)\n",
        "    X0 = X0[:, [0, 2]]\n",
        "    X1 = X1[:, [0, 2]]\n",
        "    X1 = -X1\n",
        "    X, y = shuffle(\n",
        "        np.concatenate([X0, X1], axis=0),\n",
        "        np.concatenate([np.zeros(len(X0)), np.ones(len(X1))], axis=0),\n",
        "        random_state=0)\n",
        "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "X, y = make_swiss_dataset(2000)\n",
        "y = y.astype(int)\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7ea5485-b8d5-4ad9-b337-ea537b61d795",
      "metadata": {
        "id": "a7ea5485-b8d5-4ad9-b337-ea537b61d795"
      },
      "source": [
        "**Кратко повторим теорию диффузионных моделей.**\n",
        "\n",
        "Диффузионная модель состоит из прямого и обратного процессов.\n",
        "\n",
        "Прямой процесс задаётся условным распределением $q(x_{1:T} \\mid x_0)$.\n",
        "\n",
        "Это марковская цепь, которая последовательно добавляет гауссовский шум к исходному объекту $x_0$.\n",
        "\n",
        "На каждом шаге добавляется шум некоторой величины, которая определяется расписанием дисперсий $\\{\\beta_1, \\ldots, \\beta_T\\}$.\n",
        "\n",
        "Если это расписание выбрано правильно и $T$ стремится к бесконечности (или достаточно велико), процесс сходится к стандартному гауссовскому распределению $\\mathcal{N}(0, I)$.\n",
        "\n",
        "Распределения $q$ имеют следующий вид:\n",
        "$$\n",
        " q(x_t \\mid x_{t - 1}) := \\mathcal{N}(x_t; \\sqrt{1 - \\beta_t}\\,x_{t - 1}, \\beta_t I),\n",
        " \\qquad\n",
        " q(x_{1:T}\\mid x_0) = \\prod_{t = 1}^T q(x_t \\mid x_{t - 1}).\n",
        "$$\n",
        "\n",
        "Теперь рассмотрим обратный процесс.\n",
        "\n",
        "Обратный процесс последовательно удаляет шум, начиная с чистого гауссовского шума, до тех пор, пока не будет получен объект из исходного распределения.\n",
        "\n",
        "Таким образом, диффузионная модель является вероятностной моделью с латентными переменными\n",
        "$p_\\theta(x_0) := \\int p_\\theta(x_{0:T}) \\, dx_{1:T}$,\n",
        "где латентные переменные $x_1, \\ldots, x_T$ соответствуют зашумлённым объектам, а $x_0$ — объекту из исходного распределения.\n",
        "\n",
        "Совместное распределение $p_\\theta(x_{0:T})$ определяет обратный процесс диффузии и по сути представляет собой марковскую цепь гауссовых распределений $p_\\theta(x_{t-1}\\mid x_t)$:\n",
        "\n",
        "$$\n",
        "p_\\theta(x_{0:T}) = p_\\theta(x_T)\\,\\prod_{t = 1}^T p_\\theta(x_{t-1}\\mid x_t),\n",
        "\\qquad\n",
        "p_\\theta(x_T) = \\mathcal{N}(x_T \\mid 0, I),\n",
        "$$\n",
        "$$\n",
        "p_{\\theta}(x_{t - 1}\\mid x_t) := \\mathcal{N}(x_{t - 1}; \\mu_{\\theta}(x_t, t), \\Sigma_{\\theta}(x_t, t)).\n",
        "$$\n",
        "\n",
        "Вернёмся к распределению $q(x_t \\mid x_{t - 1})$.\n",
        "\n",
        "Чтобы получить $x_t$, нам нужно итеративно вычислить $x_1, \\ldots, x_{t - 1}$.\n",
        "\n",
        "Однако благодаря свойствам гауссовского распределения это можно сделать более эффективно.\n",
        "\n",
        "Обозначим\n",
        "$\\alpha_t := 1 - \\beta_t$ и $\\bar{\\alpha}_t := \\prod_{i = 1}^t \\alpha_i$.\n",
        "\n",
        "Тогда\n",
        "$$\n",
        "q(x_t \\mid x_0) = \\mathcal{N}\\bigl(x_t;\\sqrt{\\bar{\\alpha}_t}\\,x_0, (1-\\bar{\\alpha}_t)I\\bigr). \\qquad (1)\n",
        "$$\n",
        "\n",
        "В результате модель может быть обучена путём оптимизации отдельных членов суммы вариационной нижней границы:\n",
        "$$\n",
        "L_{VLB} = \\mathbb{E}_q \\Big[\n",
        "\\underbrace{D_\\text{KL}(q(\\mathbf{x}_T \\mid \\mathbf{x}_0) \\parallel p_\\theta(\\mathbf{x}_T))}_{L_T}\n",
        "+ \\sum_{t=2}^T\n",
        "\\underbrace{D_\\text{KL}(q(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t, \\mathbf{x}_0) \\parallel p_\\theta(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t))}_{L_{t-1}}\n",
        "\\underbrace{- \\log p_\\theta(\\mathbf{x}_0 \\mid \\mathbf{x}_1)}_{L_0}\n",
        "\\Big].\n",
        "$$\n",
        "\n",
        "Для обучения необходимо выписать следующее распределение\n",
        "$q(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t, \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\boldsymbol{\\mu}(\\mathbf{x}_t, \\mathbf{x}_0), \\tilde{\\beta}_t \\mathbf{I})$:\n",
        "\n",
        "$$\n",
        "\\boldsymbol{\\mu}(\\mathbf{x}_t, \\mathbf{x}_0) =\n",
        "\\frac{\\sqrt{\\alpha_t}(1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_t}\\,\\mathbf{x}_t\n",
        "+ \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}\\beta_t}{1 - \\bar{\\alpha}_t}\\,\\mathbf{x}_0\n",
        "\\qquad (2)\n",
        "$$\n",
        "$$\n",
        "\\tilde{\\beta}_t = \\frac{1 - \\bar{\\alpha}_{t-1}}{1 - \\bar{\\alpha}_t} \\cdot \\beta_t. \\qquad (3)\n",
        "$$\n",
        "\n",
        "Подробности можно найти в работе [Denoising Diffusion Probabilistic Models (Ho et al., 2020)](https://arxiv.org/abs/2006.11239).\n",
        "\n",
        "В этой статье было показано, что при обучении с более простой функцией потерь достигаются лучшие результаты.\n",
        "\n",
        "Вспомним, что\n",
        "$$\n",
        "x_t(x_0, \\epsilon) = \\sqrt{\\bar{\\alpha}_t}\\,x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\,\\epsilon,\n",
        "\\qquad\n",
        "\\epsilon \\sim \\mathcal{N}(0, I). \\qquad (4)\n",
        "$$\n",
        "\n",
        "Пусть наша модель предсказывает $\\epsilon$ из приведённого выше выражения, обучаясь путём оптимизации следующей функции потерь:\n",
        "$$\n",
        "L^{\\text{simple}}_t = \\mathbb{E}_{x_0, \\epsilon, t}\\big[ \\|\\epsilon - \\epsilon_{\\theta}(x_t, t)\\|^2 \\big].\n",
        "$$\n",
        "\n",
        "В этом задании будет использоваться именно эта функция потерь.\n",
        "\n",
        "Для выполнения семплинга (обратного процесса) нам необходимо получить $\\mu_{\\theta}(x_t, x_0)$ из $\\epsilon_{\\theta}(x_t, t)$.\n",
        "\n",
        "Для этого найдите $\\hat{x}_0(\\epsilon_{\\theta}, x_t)$ из уравнения (4) и подставьте его в уравнение (2).\n",
        "\n",
        "_____"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c558b8e2-df9c-4098-800a-6bc9236bba73",
      "metadata": {
        "id": "c558b8e2-df9c-4098-800a-6bc9236bba73"
      },
      "outputs": [],
      "source": [
        "# Это вспомогательная функция, которая понадобится вам в этом задании.\n",
        "# Например, когда вы захотите по батчу временных меток брать из предвычисленного массива\n",
        "# соответствующие коэффициенты прямого диффузионного процесса.\n",
        "\n",
        "def _extract_into_tensor(arr: th.Tensor, timesteps: th.Tensor, broadcast_shape: Tuple):\n",
        "    \"\"\"\n",
        "    Вытаскивает значения из одномерного тензора по батчу индексов.\n",
        "\n",
        "    Параметры:\n",
        "    - arr: одномерный тензор.\n",
        "    - timesteps: батч индексов, по которым хотим извлечь значения из тензора.\n",
        "    - broadcast_shape: shape с K размерностями, к которому нужно привести итоговый тензор.\n",
        "\n",
        "    Возвращает: тензор с shape [batch_size, 1, ...], где shape имеет K размерностей.\n",
        "    \"\"\"\n",
        "    res = arr.to(device=timesteps.device)[timesteps].float()\n",
        "    while len(res.shape) < len(broadcast_shape):\n",
        "        res = res[..., None]\n",
        "    return res.expand(broadcast_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1221e597-1300-40e3-899f-e5a125763357",
      "metadata": {
        "id": "1221e597-1300-40e3-899f-e5a125763357"
      },
      "outputs": [],
      "source": [
        "# Функция, которая возвращает список «рабочих» коэффициентов betas для диффузионного процесса\n",
        "# в зависимости от длины марковской цепочки.\n",
        "\n",
        "def get_beta_schedule(num_diffusion_timesteps: int) -> th.Tensor:\n",
        "    scale = 1000 / num_diffusion_timesteps\n",
        "    beta_start = scale * 0.0001\n",
        "    beta_end = scale * 0.02\n",
        "    betas = np.linspace(beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64)\n",
        "    betas = th.from_numpy(betas).double()\n",
        "    return betas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12e6a7a9-c03d-4dab-9468-98ab87389c24",
      "metadata": {
        "id": "12e6a7a9-c03d-4dab-9468-98ab87389c24"
      },
      "outputs": [],
      "source": [
        "# Класс BaseDiffusion принимает на вход коэффициенты betas, которые задают и прямой, и обратный процессы.\n",
        "# Также в этом классе мы предварительно вычисляем величины, которые пригодятся нам позднее.\n",
        "\n",
        "class BaseDiffusion:\n",
        "    def __init__(self, betas: th.Tensor) -> None:\n",
        "        self.betas = betas\n",
        "        self.alphas = 1 - self.betas\n",
        "        self.alphas_cumprod = th.cumprod(self.alphas, dim=-1)\n",
        "        self.num_timesteps = len(self.betas)\n",
        "\n",
        "basediff = BaseDiffusion(get_beta_schedule(20))\n",
        "basediff.alphas_cumprod"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "574c0cc2-98e5-4097-a18a-86b182e847a5",
      "metadata": {
        "id": "574c0cc2-98e5-4097-a18a-86b182e847a5"
      },
      "source": [
        "### Реализуйте прямой процесс диффузии"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "669fbf56-2fd0-49cc-b25a-8cec6caec338",
      "metadata": {
        "id": "669fbf56-2fd0-49cc-b25a-8cec6caec338"
      },
      "outputs": [],
      "source": [
        "class ForwardDiffusion(BaseDiffusion):\n",
        "    def q_mean_variance(self, x0: th.Tensor, t: th.Tensor) -> th.Tensor:\n",
        "        # ====\n",
        "        # ваш код\n",
        "        # посчитайте среднее и дисперсию q(x_t | x_0) (используйте выражение (1))\n",
        "        ...\n",
        "        # ====\n",
        "        return mean, variance\n",
        "\n",
        "    def q_sample(self, x0: th.Tensor, t: th.Tensor, noise: Optional[th.Tensor]=None) -> th.Tensor:\n",
        "        if noise is None:\n",
        "            noise = th.randn_like(x0)\n",
        "        # ====\n",
        "        # ваш код\n",
        "        # просемплируйте из q(x_t | x_0) (используйте выражение (1))\n",
        "        ...\n",
        "        # ====\n",
        "        return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cec44e8-ba3e-4ae1-bfb1-6aa1c4e61999",
      "metadata": {
        "id": "1cec44e8-ba3e-4ae1-bfb1-6aa1c4e61999"
      },
      "outputs": [],
      "source": [
        "# Посмотрим на прямой процесс диффузии, применённый к SwissRoll\n",
        "\n",
        "T = 500\n",
        "forward_diffusion = ForwardDiffusion(get_beta_schedule(T))\n",
        "\n",
        "timesteps_to_plot = [1, 15, 25, 50, 75, 499]\n",
        "n_plots = len(timesteps_to_plot)\n",
        "ncols = 3\n",
        "nrows = n_plots // ncols\n",
        "\n",
        "_, axes = plt.subplots(nrows=nrows, ncols=ncols,  figsize=(4 * ncols, 4 * nrows), squeeze=False)\n",
        "for i in range(nrows):\n",
        "    for j in range(ncols):\n",
        "        idx = i * ncols + j\n",
        "\n",
        "        X_noised = forward_diffusion.q_sample(\n",
        "            x0=th.from_numpy(X),\n",
        "            t=th.ones_like(th.from_numpy(y)).long() * timesteps_to_plot[idx],\n",
        "        )\n",
        "        sns.scatterplot(x=X_noised[:, 0], y=X_noised[:, 1], hue=y, ax=axes[i, j])\n",
        "        axes[i, j].set_title(f\"timestep={timesteps_to_plot[idx]}\")\n",
        "        axes[i, j].set_xlim(-2.5, 2.5); axes[i, j].set_ylim(-2.5, 2.5)\n",
        "        axes[i, j].set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6678ffc-701a-4fab-961a-3bbb462208df",
      "metadata": {
        "id": "d6678ffc-701a-4fab-961a-3bbb462208df"
      },
      "source": [
        "### Реализуйте обратный процесс диффузии"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b18a2162-93ca-455e-b772-c1a830d92c8b",
      "metadata": {
        "id": "b18a2162-93ca-455e-b772-c1a830d92c8b"
      },
      "outputs": [],
      "source": [
        "class ReverseDiffusion(BaseDiffusion):\n",
        "    def __init__(self, *args, **kwargs) -> None:\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.alphas_cumprod_prev = th.cat(\n",
        "            [th.tensor([1.0], device=self.betas.device), self.alphas_cumprod[:-1]], dim=0\n",
        "        )\n",
        "        # ====\n",
        "        # ваш код\n",
        "        # посчитайте дисперсию распределения q(x_{t-1} | x_t, x_0) (используйте выражение (3))\n",
        "        self.variance = ...\n",
        "        # ====\n",
        "\n",
        "        # ====\n",
        "        # ваш код\n",
        "        # посчитайте коэффициенты среднего значения q(x_{t-1} | x_t, x_0) (используйте выражение (2))\n",
        "        self.xt_coef = ...\n",
        "        self.x0_coef = ...\n",
        "        # ====\n",
        "\n",
        "    def get_x0(self, xt: th.Tensor, eps: th.Tensor, t: th.Tensor) -> th.Tensor:\n",
        "        # ====\n",
        "        # ваш код\n",
        "        # посчитайте x0 (используйте выражения (4) и (2))\n",
        "        ...\n",
        "        # ====\n",
        "        return x0\n",
        "\n",
        "    def q_posterior_mean_variance(\n",
        "        self, xt: th.Tensor, eps: th.Tensor, t: th.Tensor\n",
        "    ) -> Tuple[th.Tensor, th.Tensor]:\n",
        "        # ====\n",
        "        # ваш код\n",
        "        # посчитайте среднее и дисперсию распределения q(x_{t-1} | x_t, x_0) (используйте выражения (2) и (3))\n",
        "        ...\n",
        "        # ====\n",
        "        return mean, variance\n",
        "\n",
        "    def p_sample(self, xt: th.Tensor, eps: th.Tensor, t: th.Tensor) -> th.Tensor:\n",
        "        # прочитайте код для одного шага генерации внимательно\n",
        "        mean, variance = self.q_posterior_mean_variance(xt=xt, eps=eps, t=t)\n",
        "        noise = th.randn_like(xt, device=xt.device)\n",
        "\n",
        "        nonzero_mask = th.ones_like(t) # чтобы не добавлять шум, если t = 0\n",
        "        nonzero_mask[t == 0] = 0\n",
        "        nonzero_mask = _extract_into_tensor(\n",
        "            nonzero_mask, th.arange(nonzero_mask.shape[0]), xt.shape\n",
        "        )\n",
        "        nonzero_mask = nonzero_mask.to(xt.device)\n",
        "\n",
        "        sample = mean + nonzero_mask * variance.sqrt() * noise\n",
        "        return sample.float()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03a5237b-2302-4db8-ae72-d9d72ce1c426",
      "metadata": {
        "id": "03a5237b-2302-4db8-ae72-d9d72ce1c426"
      },
      "source": [
        "### Реализуем архитектуру нейронной сети для предсказания шума"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e13db8a-3c49-467a-90e5-abbfc0ca0a7b",
      "metadata": {
        "id": "1e13db8a-3c49-467a-90e5-abbfc0ca0a7b"
      },
      "outputs": [],
      "source": [
        "# Заметьте, что модель на вход принимает не только зашумлённый объект,\n",
        "# но также момент времени и индекс класса.\n",
        "\n",
        "class ConditionalMLP(nn.Module):\n",
        "    def __init__(self, d_in: int, T: int, n_classes: int, hidden_dim: Optional[int]=128):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.x_proj = nn.Linear(d_in, self.hidden_dim)\n",
        "        self.t_proj = nn.Embedding(T, self.hidden_dim)\n",
        "        self.y_embed = nn.Embedding(n_classes, self.hidden_dim)\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim, 2 * self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(2 * self.hidden_dim, d_in)\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def device(self):\n",
        "        return next(self.parameters()).device\n",
        "\n",
        "    def forward(self, x, t, y):\n",
        "        \"\"\"\n",
        "        Параметры:\n",
        "        - x: зашумлённая картинка.\n",
        "        - t: счётчик времени/уровень шума.\n",
        "        - y: индекс класса, который нужно сгенерировать.\n",
        "        \"\"\"\n",
        "        x = self.x_proj(x)\n",
        "        t = self.t_proj(t.int())\n",
        "        y = self.y_embed(y)\n",
        "        x = x + t + y\n",
        "        x = F.gelu(x)\n",
        "        return self.backbone(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "264507c7-ea16-4799-932b-018d662004ab",
      "metadata": {
        "id": "264507c7-ea16-4799-932b-018d662004ab"
      },
      "source": [
        "### Реализуйте DDPM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d3e0283-dfb5-43a2-b833-82aee9f9ea29",
      "metadata": {
        "id": "7d3e0283-dfb5-43a2-b833-82aee9f9ea29"
      },
      "outputs": [],
      "source": [
        "class DDPM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        betas: th.Tensor,\n",
        "        model: nn.Module,\n",
        "        shape: Optional[th.Tensor] = None,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.forward_diffusion = ForwardDiffusion(betas=betas)\n",
        "        self.reverse_diffusion = ReverseDiffusion(betas=betas)\n",
        "        self.model = model\n",
        "        self.num_timesteps = len(betas)\n",
        "\n",
        "        self.register_buffer(\"betas\", betas)\n",
        "        self.register_buffer(\"shape\", shape)\n",
        "\n",
        "    @property\n",
        "    def device(self) -> None:\n",
        "        return next(self.parameters()).device\n",
        "\n",
        "    @th.no_grad()\n",
        "    def sample(self, y: th.Tensor) -> th.Tensor:\n",
        "        num_samples = y.shape[0]\n",
        "        x = th.randn((num_samples, *self.shape), device=self.device, dtype=th.float32)\n",
        "        indices = list(range(self.num_timesteps))[::-1]\n",
        "\n",
        "        for i in tqdm(indices):\n",
        "            t = th.tensor([i] * num_samples, device=x.device)\n",
        "            # ====\n",
        "            # ваш код\n",
        "            # 1) предскажите шум с помощью модели\n",
        "            # 2) сделайте шаг разшумления\n",
        "            ...\n",
        "            # ====\n",
        "        return x, y\n",
        "\n",
        "    def train_loss(self, x0: th.Tensor, y: th.Tensor) -> th.Tensor:\n",
        "        if self.shape is None:\n",
        "            self.shape = th.tensor(list(x0.shape)[1:], device=\"cpu\")\n",
        "        t = th.randint(0, self.num_timesteps, size=(x0.size(0),), device=x0.device)\n",
        "        noise = th.randn_like(x0)\n",
        "        # ====\n",
        "        # ваш код\n",
        "        # 1) зашумите x0 и получите xt\n",
        "        # 2) предскажите по xt наложенный на него шум\n",
        "        ...\n",
        "        # ====\n",
        "        loss = F.mse_loss(eps, noise)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ddaa895-25a4-4528-9188-250eb33c1a52",
      "metadata": {
        "id": "8ddaa895-25a4-4528-9188-250eb33c1a52"
      },
      "outputs": [],
      "source": [
        "# Теперь давайте обучим наш DDPM.\n",
        "\n",
        "def train_model(\n",
        "    ddpm: DDPM,\n",
        "    dataloader: DataLoader,\n",
        "    *,\n",
        "    lr: float,\n",
        "    n_iters: int,\n",
        "    device: str = \"cpu\",\n",
        "    log_every: int = 500\n",
        "):\n",
        "    ddpm.to(device)\n",
        "\n",
        "    optimizer = th.optim.Adam(ddpm.model.parameters(), lr=lr)\n",
        "\n",
        "    step = 0\n",
        "    curr_loss_gauss = 0.0\n",
        "    curr_count = 0\n",
        "    optimizer.zero_grad()\n",
        "    data_iter = iter(dataloader)\n",
        "    while step < n_iters:\n",
        "        try:\n",
        "            batch = next(data_iter)\n",
        "        except StopIteration:\n",
        "            data_iter = iter(dataloader)\n",
        "            batch = next(data_iter)\n",
        "\n",
        "        x, y = batch[\"x\"].to(device), batch[\"y\"].to(device)\n",
        "\n",
        "        loss = ddpm.train_loss(x, y)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        curr_count += len(x)\n",
        "        curr_loss_gauss += loss.item() * len(x)\n",
        "\n",
        "        if (step + 1) % log_every == 0:\n",
        "            gloss = np.around(curr_loss_gauss / curr_count, 4)\n",
        "            print(f\"Step {(step + 1)}/{n_iters} Loss: {gloss}\")\n",
        "            curr_count = 0\n",
        "            curr_loss_gauss = 0.0\n",
        "\n",
        "        step += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ae3505d-e2b3-4d29-be82-10dc0ee5fa5e",
      "metadata": {
        "id": "9ae3505d-e2b3-4d29-be82-10dc0ee5fa5e"
      },
      "outputs": [],
      "source": [
        "T = 500\n",
        "BATCH_SIZE = 1024\n",
        "LR = 0.01\n",
        "N_ITERS = 10000\n",
        "\n",
        "model = ConditionalMLP(d_in=2, T=T, n_classes=2)\n",
        "device = \"cpu\" # можно считать на гпу, но цпу должно быть достаточно\n",
        "\n",
        "ddpm = DDPM(betas=get_beta_schedule(T), model=model)\n",
        "dataloader = get_labeled_data_loader(X, y, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "train_model(\n",
        "    ddpm=ddpm,\n",
        "    dataloader=dataloader,\n",
        "    lr=LR,\n",
        "    n_iters=N_ITERS,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bf2530c-18eb-4423-9e9d-fc4c3531119b",
      "metadata": {
        "id": "4bf2530c-18eb-4423-9e9d-fc4c3531119b"
      },
      "outputs": [],
      "source": [
        "# Теперь давайте посмотрим, что наша модель научилась генерировать (должно быть похоже на наш SwissRoll датасет)\n",
        "\n",
        "num_samples = X.shape[0]\n",
        "ys = th.randint(0, 2, size=(num_samples,), device=device)\n",
        "Xs, ys = ddpm.sample(ys)\n",
        "\n",
        "_, (ax_gen, ax_real) = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
        "sns.scatterplot(x=Xs[:, 0].cpu().numpy(), y=Xs[:, 1].cpu().numpy(), hue=ys.cpu().numpy(), ax=ax_gen); ax_gen.set_axis_off();\n",
        "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, ax=ax_real); ax_real.set_axis_off();\n",
        "\n",
        "ax_gen.set_title(\"generated\")\n",
        "ax_real.set_title(\"real\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VNtliN5O5Ncl",
      "metadata": {
        "id": "VNtliN5O5Ncl"
      },
      "source": [
        "## Classifier-free guidance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g_WrDiYE6JpH",
      "metadata": {
        "id": "g_WrDiYE6JpH"
      },
      "source": [
        "К этому моменту мы реализовали базовый алгоритм для диффузионных моделей DDPM.\n",
        "\n",
        "Теперь реализуем **classifier-free guidance** — технику для улучшения class-conditional генерации, которую мы разбирали на лекции.\n",
        "\n",
        "Итоговая формула очень простая:\n",
        "$$\n",
        "\\hat{\\epsilon}_\\theta(x_t, t, y) =\n",
        "\\epsilon_\\theta(x_t, t, y=\\varnothing)\n",
        "+ s\\bigl(\\epsilon_\\theta(x_t, t, y) - \\epsilon_\\theta(x_t, t, y=\\varnothing)\\bigr), \\qquad (1)\n",
        "$$\n",
        "где:\n",
        "- $\\epsilon_\\theta(x_t, t, y)$ — модель, которую мы обучаем;\n",
        "- $s$ — guidance scale (контролирует силу guidance);\n",
        "- $\\hat{\\epsilon}_\\theta(x_t, t, y)$ — итоговая модель для предсказания шума;\n",
        "- $y$ — класс, который мы хотим сгенерировать;\n",
        "- $y = \\varnothing$ означает, что в нейронную сеть подаётся специальный «пустой» класс для unconditional-режима.\n",
        "\n",
        "**Обучение** происходит следующим образом:\n",
        "\n",
        "1. Семплируем\n",
        "   $$\n",
        "   (x_0, c) \\sim p_{\\text{data}}, \\quad\n",
        "   t \\sim \\text{Uniform}\\{1, \\ldots, T\\}, \\quad\n",
        "   \\epsilon \\sim \\mathcal{N}(0, I).\n",
        "   $$\n",
        "2. Зашумляем данные:\n",
        "   $$\n",
        "   x_t = \\sqrt{\\bar{\\alpha}_t}\\,x_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\,\\epsilon.\n",
        "   $$\n",
        "3. С вероятностью $p$ выбираем, учим ли мы модель в unconditional- или conditional-режиме:\n",
        "   - unconditional:\n",
        "     $$\n",
        "     \\|\\epsilon_\\theta(x_t, t, y=\\varnothing) - \\epsilon\\|_2^2,\n",
        "     $$\n",
        "   - conditional:\n",
        "     $$\n",
        "     \\|\\epsilon_\\theta(x_t, t, y=c) - \\epsilon\\|_2^2.\n",
        "     $$\n",
        "\n",
        "*Замечание.* Логика выбора unconditional-/conditional-режима обучения реализована за вас в классе `LabeledDataset` (лежит в `utils.py`). Это сделано затем, чтобы можно было переиспользовать функцию `train_model` без изменений. Обратите внимание на параметр `drop_label`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DDsSAT3S5Ncn",
      "metadata": {
        "id": "DDsSAT3S5Ncn"
      },
      "source": [
        "### Реализуйте Classifier-free Guidance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xHIH44QO5Ncn",
      "metadata": {
        "id": "xHIH44QO5Ncn"
      },
      "outputs": [],
      "source": [
        "class DDPMWithCFG(DDPM):\n",
        "    @th.no_grad()\n",
        "    def sample_with_cfg(self, y: th.Tensor, guidance_scale: float=0., null_label: int=2):\n",
        "        \"\"\"\n",
        "        Параметры:\n",
        "        - y: метка класса;\n",
        "        - guidance_scale:\n",
        "            - 0: unconditional-режим;\n",
        "            - 1: conditional-режим, честно восстанавливающий распределение;\n",
        "            - чем выше значение, тем сильнее влияние класса;\n",
        "        - null_label: заранее подготовленный индекс класса, отвечающий за unconditional-обучение.\n",
        "        \"\"\"\n",
        "        assert self.shape is not None\n",
        "        num_samples = y.shape[0]\n",
        "        x = th.randn((num_samples, *self.shape), device=self.device, dtype=th.float32)\n",
        "        indices = list(range(self.num_timesteps))[::-1]\n",
        "\n",
        "        for i in tqdm(indices):\n",
        "            t = th.tensor([i] * num_samples, device=x.device)\n",
        "            # ====\n",
        "            # ваш код\n",
        "            # 1) предскажите epsilon с крышечкой с помощью метод `_predict_eps_hat`\n",
        "            # 2) сделайте шаг разшумления\n",
        "            ...\n",
        "            # ====\n",
        "        return x, y\n",
        "\n",
        "    def _predict_eps_hat(self, x: th.Tensor, t: th.Tensor, y: th.Tensor, guidance_scale: float, null_label: int):\n",
        "        null_y = null_label * th.ones_like(y)\n",
        "        # ====\n",
        "        # ваш код\n",
        "        # предскажите epsilon с крышечкой с помощью модели (используйте выражение (1))\n",
        "        ...\n",
        "        # ====\n",
        "        return eps_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DvjmEy3z5Nco",
      "metadata": {
        "id": "DvjmEy3z5Nco"
      },
      "outputs": [],
      "source": [
        "T = 500\n",
        "BATCH_SIZE = 1024\n",
        "LR = 0.01\n",
        "N_ITERS = 30000\n",
        "DROP_LABEL = 0.4\n",
        "\n",
        "model = ConditionalMLP(d_in=2, T=T, n_classes=2+1)\n",
        "device = \"cpu\" # можно считать на гпу, но цпу должно быть достаточно\n",
        "\n",
        "ddpm = DDPMWithCFG(betas=get_beta_schedule(T), model=model)\n",
        "dataloader = get_labeled_data_loader(X, y, batch_size=BATCH_SIZE, shuffle=True, drop_label=DROP_LABEL)\n",
        "\n",
        "train_model(\n",
        "    ddpm=ddpm,\n",
        "    dataloader=dataloader,\n",
        "    lr=LR,\n",
        "    n_iters=N_ITERS,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FeHU1_8g5Ncp",
      "metadata": {
        "id": "FeHU1_8g5Ncp"
      },
      "outputs": [],
      "source": [
        "# Давайте посмотрим на качество генерации c разным guidance scale\n",
        "\n",
        "guidance_scale_to_plot = [1.0, 2.0, 3.0, 4.0, 16.0]\n",
        "n_plots = len(guidance_scale_to_plot) + 1\n",
        "ncols = 3\n",
        "nrows = n_plots // ncols\n",
        "\n",
        "num_samples = X.shape[0]\n",
        "ys = th.randint(0, 2, size=(num_samples,), device=device)\n",
        "\n",
        "_, axes = plt.subplots(nrows=nrows, ncols=ncols,  figsize=(4 * ncols, 4 * nrows), squeeze=False)\n",
        "for i in range(nrows):\n",
        "    for j in range(ncols):\n",
        "        idx = i * ncols + j\n",
        "\n",
        "        if idx == 0:\n",
        "            sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, ax=axes[i, j])\n",
        "            axes[i, j].set_title(\"real\")\n",
        "        else:\n",
        "            idx = idx - 1\n",
        "            Xs, ys = ddpm.sample_with_cfg(ys, guidance_scale=guidance_scale_to_plot[idx], null_label=2)\n",
        "            sns.scatterplot(x=Xs[:, 0].cpu().numpy(), y=Xs[:, 1].cpu().numpy(), hue=ys.cpu().numpy(), ax=axes[i, j])\n",
        "            axes[i, j].set_title(f\"guidance_scale={guidance_scale_to_plot[idx]}\")\n",
        "        axes[i, j].set_xlim(-2.5, 2.5); axes[i, j].set_ylim(-2.5, 2.5)\n",
        "        axes[i, j].set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5c54703-6426-4614-9aac-5267fdb3ec31",
      "metadata": {
        "id": "a5c54703-6426-4614-9aac-5267fdb3ec31"
      },
      "source": [
        "**Замечания про classifier-free guidance:**\n",
        "- генерирует семплы, которые более вероятны для конкретного класса (чем выше guidance scale, тем меньше пересечения между генерациями разных классов);\n",
        "- слишком большой guidance scale может приводить к выбросам"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dd45b60-4268-46cc-bcfd-ce5d5c66dbcc",
      "metadata": {
        "id": "2dd45b60-4268-46cc-bcfd-ce5d5c66dbcc"
      },
      "source": [
        "## Ускоренный семплинг из DDPM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e051a2c-48a8-456f-a0f4-97f4390a2fd6",
      "metadata": {
        "id": "2e051a2c-48a8-456f-a0f4-97f4390a2fd6"
      },
      "source": [
        "На данном этапе мы реализовали DDPM и технику classifier-free guidance.\n",
        "В текущей реализации для генерации нужно делать столько же шагов, сколько вершин в марковской цепочке, а в случае использования classifier-free guidance — в два раза больше.\n",
        "Это не критично для нашего игрушечного датасета SwissRoll, однако чем сложнее датасет и больше размерность данных, тем дороже становится каждый шаг генерации.\n",
        "\n",
        "В этой части мы реализуем математически обоснованный способ пропускать некоторые вершины марковской цепочки для более быстрого семплинга из DDPM. Этот подход мы также обсуждали на лекции.\n",
        "\n",
        "Вкратце вспомним, что там происходило.\n",
        "\n",
        "Пусть у нас есть DDPM с максимальным индексом вершины в марковской цепочке $T$, и мы хотим семплировать за $I < T$ шагов.\n",
        "При этом важно, чтобы мы могли переиспользовать предобученную на $T$ шагах диффузионную модель $\\epsilon_\\theta(x_t, t)$, где $t \\in \\{1, \\ldots, T\\}$.\n",
        "\n",
        "Для этого мы искали более короткую марковскую цепочку длины $I$ (вершины будут проиндексированы $i \\in \\{1, \\ldots, I\\}$), которая является подцепочкой исходной более длинной:\n",
        "\n",
        "1. Мы выбрали, каким вершинам исходной длинной цепочки будет соответствовать новая цепочка. Для этого мы задали функцию\n",
        "   $\\tau: \\{1, \\ldots, I\\} \\to \\{1, \\ldots, T\\}$,\n",
        "   которая отображает временные индексы новой цепочки в индексы старой. При этом важно, чтобы $\\tau(I) = T$, чтобы новая цепочка всё так же заканчивалась в стандартном гауссовском распределении.\n",
        "\n",
        "2. Далее мы формализовали наше желание, чтобы новая короткая цепочка была подцепочкой исходной. Для этого мы выровняли их соответствующие маргинальные распределения:\n",
        "   $$\n",
        "   q_{\\text{new}}(x_i) = q(x_{t = \\tau(i)}).\n",
        "   $$\n",
        "\n",
        "3. Это условие позволило нам найти параметры короткой диффузионной марковской цепочки:\n",
        "   $$\n",
        "   \\beta_{\\text{new}, i} = 1 - \\alpha_{\\text{new}, i}\n",
        "   = 1 - \\frac{\\bar{\\alpha}_{\\tau(i)}}{\\bar{\\alpha}_{\\tau(i - 1)}}. \\qquad (1)\n",
        "   $$\n",
        "\n",
        "4. Также это позволило нам переиспользовать предобученную на длинной цепочке диффузионную модель $\\epsilon_\\theta(x_t, t)$:\n",
        "   $$\n",
        "   \\epsilon_{\\text{new}, \\theta}(x_i, i) = \\epsilon_\\theta(x_t = x_i, t = \\tau(i)). \\qquad (2)\n",
        "   $$\n",
        "\n",
        "Таким образом, нам нужно сделать класс DDPM с правильными параметрами новой, более короткой марковской цепочки, определёнными выше, и корректным переиспользованием предобученной диффузионной модели, чтобы семплировать за $I < T$ шагов.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a90cd92c-6e37-4d60-a15a-619301d14f29",
      "metadata": {
        "id": "a90cd92c-6e37-4d60-a15a-619301d14f29"
      },
      "source": [
        "### Реализуйте WrappedModel и SpacedDDPMWithCFG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdce6366-7161-4edd-9b1a-dcd4cc8f6820",
      "metadata": {
        "id": "fdce6366-7161-4edd-9b1a-dcd4cc8f6820"
      },
      "outputs": [],
      "source": [
        "class WrappedModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Класс обёртка для предобученной диффузионной модели epsilon(x_t, t),\n",
        "        которая позволяет учитывать отображение tau счётчиков времени из нового в старый.\n",
        "\n",
        "    Параметры:\n",
        "    - model: предобученная диффузионная модель epsilon(x_t, t)\n",
        "    - timestep_map: массив, который по индексу i содержит время tau(i)\n",
        "    \"\"\"\n",
        "    def __init__(self, model: nn.Module, timestep_map: List):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.timestep_map = timestep_map\n",
        "\n",
        "    @property\n",
        "    def device(self):\n",
        "        return next(self.model.parameters()).device\n",
        "\n",
        "    def forward(self, x: th.Tensor, t: th.Tensor, *args, **kwargs) -> th.Tensor:\n",
        "        # ====\n",
        "        # ваш код\n",
        "        # посчитайте счётчик времени new_t старой (длинной) цепочки по счётчику времени t новой (короткой) цепочки\n",
        "        # тут было бы нагляднее использовать i вместо t,\n",
        "        #     но ранее в коде мы зафиксировали, что нейронная сеть принимает именованный аргумент t.\n",
        "        ...\n",
        "        # ====\n",
        "        return self.model(x, new_t, *args, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28584260-f7d5-48d0-94de-194057bcf402",
      "metadata": {
        "id": "28584260-f7d5-48d0-94de-194057bcf402"
      },
      "outputs": [],
      "source": [
        "class SpacedDDPMWithCFG(DDPMWithCFG):\n",
        "    \"\"\"\n",
        "    Класс для адаптации DDPM для более короткой марковской цепочки.\n",
        "    Переопределяет параметры betas и использование нейронной сети.\n",
        "\n",
        "    Параметры:\n",
        "    - kwargs: параметры, которые задают обычный DDPM (длинную цепочку);\n",
        "    - use_timesteps: массив индексов длинной цепочки, по которым мы хотели бы ходить.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, use_timesteps: Optional[Tuple]=None, **kwargs):\n",
        "        # Если use_timesteps не задан, будем ходить по всем вершинам длинной цепочки\n",
        "        if use_timesteps is None:\n",
        "            use_timesteps = list(range(len(kwargs[\"betas\"])))\n",
        "        self.use_timesteps = set(use_timesteps)\n",
        "\n",
        "        base_ddpm = DDPM(**kwargs)\n",
        "\n",
        "        last_alpha_cumprod = 1.0\n",
        "        new_betas = []\n",
        "        for t, alpha_cumprod in enumerate(base_ddpm.forward_diffusion.alphas_cumprod):\n",
        "            if t in self.use_timesteps:\n",
        "                # ====\n",
        "                # ваш код\n",
        "                # посчитайте параметры короткой марковской цепочки и положите их new_betas\n",
        "                ...\n",
        "                # ====\n",
        "        kwargs = deepcopy(kwargs)\n",
        "        kwargs[\"betas\"] = th.tensor(new_betas)\n",
        "        kwargs[\"model\"] = WrappedModel(kwargs[\"model\"], use_timesteps)\n",
        "        super().__init__(**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6932cc36-8ff7-4659-a7c4-ddcbb61beb6e",
      "metadata": {
        "id": "6932cc36-8ff7-4659-a7c4-ddcbb61beb6e"
      },
      "outputs": [],
      "source": [
        "# Вспомогательная функция, которая позволяет создать SpacedDDPMWithCFG по инстансу DDPM\n",
        "# и задать количество шагов, которое мы хотим использовать.\n",
        "# Эта функция распределяет шаги равномерно по вершинам (это частный случай и может быть неоптимален).\n",
        "\n",
        "def get_spaced_ddpm(ddpm: DDPMWithCFG, num_timesteps: int=None):\n",
        "    if num_timesteps is not None:\n",
        "        num_timesteps = min(num_timesteps, ddpm.num_timesteps)\n",
        "        use_timesteps = np.linspace(1, ddpm.num_timesteps, num=num_timesteps+1).astype(\"int\")[1:]\n",
        "    else:\n",
        "        use_timesteps = None\n",
        "\n",
        "    return SpacedDDPMWithCFG(\n",
        "        use_timesteps=use_timesteps,\n",
        "        betas=ddpm.betas,\n",
        "        model=ddpm.model,\n",
        "        shape=ddpm.shape,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f0ef7a9-4ca8-4357-9943-f4bd9edb86b8",
      "metadata": {
        "id": "0f0ef7a9-4ca8-4357-9943-f4bd9edb86b8"
      },
      "outputs": [],
      "source": [
        "# Давайте посмотрим на качество генерации при уменьшении количества шагов семплирования (guidance_scale = 1).\n",
        "\n",
        "guidance_scale = 1.\n",
        "\n",
        "num_timesteps_to_plot = [500, 250, 100, 50, 25, 10]\n",
        "n_plots = len(num_timesteps_to_plot)\n",
        "ncols = 3\n",
        "nrows = n_plots // ncols\n",
        "\n",
        "num_samples = X.shape[0]\n",
        "ys = th.randint(0, 2, size=(num_samples,), device=device)\n",
        "\n",
        "_, axes = plt.subplots(nrows=nrows, ncols=ncols,  figsize=(4 * ncols, 4 * nrows), squeeze=False)\n",
        "for i in range(nrows):\n",
        "    for j in range(ncols):\n",
        "        idx = i * ncols + j\n",
        "\n",
        "        spaced_ddpm = get_spaced_ddpm(ddpm, num_timesteps_to_plot[idx])\n",
        "        Xs, ys = spaced_ddpm.sample_with_cfg(ys, guidance_scale=guidance_scale, null_label=2)\n",
        "        sns.scatterplot(x=Xs[:, 0].detach().cpu().numpy(), y=Xs[:, 1].detach().cpu().numpy(), hue=ys.detach().cpu().numpy(), ax=axes[i, j])\n",
        "        axes[i, j].set_title(f\"num_timesteps={num_timesteps_to_plot[idx]}\")\n",
        "        axes[i, j].set_xlim(-2.5, 2.5); axes[i, j].set_ylim(-2.5, 2.5)\n",
        "        axes[i, j].set_axis_off()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sMgnxwVkIeNz",
      "metadata": {
        "id": "sMgnxwVkIeNz"
      },
      "outputs": [],
      "source": [
        "# Давайте посмотрим на качество генерации при уменьшении количества шагов семплирования (guidance_scale = 3).\n",
        "guidance_scale = 3\n",
        "\n",
        "num_timesteps_to_plot = [500, 250, 100, 50, 25, 10]\n",
        "n_plots = len(num_timesteps_to_plot)\n",
        "ncols = 3\n",
        "nrows = n_plots // ncols\n",
        "\n",
        "num_samples = X.shape[0]\n",
        "ys = th.randint(0, 2, size=(num_samples,), device=device)\n",
        "\n",
        "_, axes = plt.subplots(nrows=nrows, ncols=ncols,  figsize=(4 * ncols, 4 * nrows), squeeze=False)\n",
        "for i in range(nrows):\n",
        "    for j in range(ncols):\n",
        "        idx = i * ncols + j\n",
        "\n",
        "        spaced_ddpm = get_spaced_ddpm(ddpm, num_timesteps_to_plot[idx])\n",
        "        Xs, ys = spaced_ddpm.sample_with_cfg(ys, guidance_scale=guidance_scale, null_label=2)\n",
        "        sns.scatterplot(x=Xs[:, 0].detach().cpu().numpy(), y=Xs[:, 1].detach().cpu().numpy(), hue=ys.detach().cpu().numpy(), ax=axes[i, j])\n",
        "        axes[i, j].set_title(f\"num_timesteps={num_timesteps_to_plot[idx]}\")\n",
        "        axes[i, j].set_xlim(-2.5, 2.5); axes[i, j].set_ylim(-2.5, 2.5)\n",
        "        axes[i, j].set_axis_off()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "626e25e6-e1ed-4a30-80e7-e8304b7a00b6",
      "metadata": {
        "id": "626e25e6-e1ed-4a30-80e7-e8304b7a00b6"
      },
      "source": [
        "Отлично! У нас получилось значительно сократить количество шагов генерации без особой потери в качестве!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e076e999-ad33-4a50-b1e5-1716059de645",
      "metadata": {
        "id": "e076e999-ad33-4a50-b1e5-1716059de645"
      },
      "source": [
        "## MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1a79f1d-b29f-4344-a6fa-5ee28984ef61",
      "metadata": {
        "id": "e1a79f1d-b29f-4344-a6fa-5ee28984ef61"
      },
      "source": [
        "В предыдущей части мы работали с двумерным датасетом SwissRoll.\n",
        "Он может показаться слишком простым. Так и есть: именно из-за своей простоты он удобен для проверки и дебага нашего кода.\n",
        "\n",
        "Теперь, когда мы видим, что наш код работает, протестируем его на чём-то посложнее — на MNIST!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b4634da-7b00-48c5-81d1-e9a6a3ab3d2a",
      "metadata": {
        "id": "6b4634da-7b00-48c5-81d1-e9a6a3ab3d2a"
      },
      "outputs": [],
      "source": [
        "# Скачаем датасет\n",
        "\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "\n",
        "def mnist_to_train_range(X):\n",
        "    return ((X.astype(\"float32\") / 255.) - 0.5) * 2\n",
        "\n",
        "def mnist_from_train_range(X):\n",
        "    return (((X.astype(\"float32\") + 1.0) / 2) * 255.).astype(\"int\")\n",
        "\n",
        "dataset = MNIST(\"./datasets\", download=True, train=True)\n",
        "X = dataset.data.numpy().astype(\"float32\")[:, None]\n",
        "y = dataset.targets.numpy()\n",
        "mnist_loader = get_labeled_data_loader(mnist_to_train_range(X), y, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4458e1d-9df7-4878-8ec2-9ca78c760a01",
      "metadata": {
        "id": "e4458e1d-9df7-4878-8ec2-9ca78c760a01"
      },
      "outputs": [],
      "source": [
        "# Вспомогательная функция для визуализации\n",
        "\n",
        "def show_images(images, ys, title=\"\"):\n",
        "    if type(images) is th.Tensor:\n",
        "        images = images.detach().cpu().numpy()\n",
        "        ys = ys.detach().cpu().numpy()\n",
        "\n",
        "    rows = int(len(images) ** (1 / 2))\n",
        "    cols = round(len(images) / rows)\n",
        "    fig = plt.figure(figsize=(cols*1.5, rows*1.5))\n",
        "\n",
        "    idx = 0\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            fig.add_subplot(rows, cols, idx + 1)\n",
        "\n",
        "            if idx < len(images):\n",
        "                plt.imshow(images[idx][0], cmap=\"gray\")\n",
        "                plt.title(f\"{int(ys[idx])}\", fontsize=10)\n",
        "                plt.tick_params(bottom = False, left=False, labelbottom=False, labelleft=False)\n",
        "                idx += 1\n",
        "    plt.show()\n",
        "\n",
        "def show_first_batch(loader, batch_size=16):\n",
        "    for batch in loader:\n",
        "        show_images(batch[\"x\"][:batch_size], batch[\"y\"][:batch_size], \"Images in the first batch\")\n",
        "        break\n",
        "\n",
        "show_first_batch(mnist_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "add84fd1-17b3-4c78-84e5-18495ddad23f",
      "metadata": {
        "id": "add84fd1-17b3-4c78-84e5-18495ddad23f"
      },
      "source": [
        "### Визуализируйте прямой процесс диффузии"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfc53188-6fa5-4091-b050-20dcced7ef39",
      "metadata": {
        "id": "cfc53188-6fa5-4091-b050-20dcced7ef39"
      },
      "outputs": [],
      "source": [
        "T = 1000\n",
        "forward_diffusion = ForwardDiffusion(get_beta_schedule(T))\n",
        "\n",
        "timesteps_to_plot = [1, 30, 50, 100, 150, 250, 500, 999]\n",
        "\n",
        "image = next(iter(mnist_loader))[\"x\"][:1, 0]\n",
        "\n",
        "# ====\n",
        "# ваш код\n",
        "# по аналогии с тем, как мы делали для SwissRoll,\n",
        "# примените прямой процесс диффузии к переменной image и\n",
        "# визуализируйте зашумлённую картинку в разные моменты времени (включая самый последний шаг)\n",
        "...\n",
        "# ===="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bb7a2fc-16d8-45b0-bb7c-63adff11d093",
      "metadata": {
        "id": "4bb7a2fc-16d8-45b0-bb7c-63adff11d093"
      },
      "source": [
        "### Обучите диффузионную модель и получите хорошие генерации с помощью неё"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3062c576-9ef7-4599-a22a-8fe60838a686",
      "metadata": {
        "id": "3062c576-9ef7-4599-a22a-8fe60838a686"
      },
      "outputs": [],
      "source": [
        "T = 1000\n",
        "# ====\n",
        "# ваш код\n",
        "# выберите гиперпараметры\n",
        "LR = ... # 0.0001 <= LR <= 0.01\n",
        "N_ITERS = ... # N_ITERS >= 5000\n",
        "DROP_LABEL = ... # 0.1 <= DROP_LABEL <= 0.5\n",
        "BATCH_SIZE = ... # 256 <= BATCH_SIZE <=  2048\n",
        "# ====\n",
        "\n",
        "model = MyUNet(use_null_cond=True)\n",
        "\n",
        "ddpm = DDPMWithCFG(betas=get_beta_schedule(T), model=model)\n",
        "dataloader = get_labeled_data_loader(mnist_to_train_range(X), y, batch_size=BATCH_SIZE, shuffle=True, drop_label=DROP_LABEL)\n",
        "\n",
        "train_model(\n",
        "    ddpm=ddpm,\n",
        "    dataloader=dataloader,\n",
        "    lr=LR,\n",
        "    n_iters=N_ITERS,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b3b4b9b-a824-4964-b44f-940fc4bd9976",
      "metadata": {
        "id": "1b3b4b9b-a824-4964-b44f-940fc4bd9976"
      },
      "outputs": [],
      "source": [
        "# Теперь давайте посмотрим, что наша модель научилась генерировать\n",
        "\n",
        "num_samples = 16\n",
        "ys = th.randint(10, size=(num_samples,), device=device)\n",
        "Xs, ys = ddpm.sample(ys)\n",
        "show_images(Xs, ys)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3c10df9-a8d6-4067-af79-861ee911edc4",
      "metadata": {
        "id": "a3c10df9-a8d6-4067-af79-861ee911edc4"
      },
      "source": [
        "### Сравните генерацию с помощью classifier-free с разными guidance scale"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcd1b39e-6342-4f5e-ae76-808286356700",
      "metadata": {
        "id": "fcd1b39e-6342-4f5e-ae76-808286356700"
      },
      "source": [
        "Сейчас для генерации в диффузионной модели нам нужно делать 1000 вызовов нейросети.\n",
        "\n",
        "С classifier-free guidance потребуется 2000 вызовов.\n",
        "\n",
        "Это долго, и с таким числом шагов сложно быстро экспериментировать.\n",
        "\n",
        "Поэтому сначала подберём меньшее количество шагов семплирования без classifier-free guidance, при котором качество генерации остаётся хорошим, а затем будем использовать это количество шагов для сравнения разных значений guidance scale.\n",
        "\n",
        "Используйте: `spaced_ddpm = get_spaced_ddpm(ddpm, ???)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01b879cf-9e81-4d9b-9ba6-d68f01f6e3f0",
      "metadata": {
        "id": "01b879cf-9e81-4d9b-9ba6-d68f01f6e3f0"
      },
      "outputs": [],
      "source": [
        "n_steps = ...\n",
        "spaced_ddpm = get_spaced_ddpm(ddpm, n_steps)\n",
        "# ====\n",
        "# ваш код\n",
        "# найдите меньшее число, чем T = 1000, шагов, с которым можно получать хорошие генерации.\n",
        "# визуализируйте генерации с этим итоговым числом шагов\n",
        "...\n",
        "# ===="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b80c468-2cfd-4518-944e-06f3e0055857",
      "metadata": {
        "id": "1b80c468-2cfd-4518-944e-06f3e0055857"
      },
      "outputs": [],
      "source": [
        "# ====\n",
        "# ваш код\n",
        "# визуализируйте генерации, полученные с помощью classifier-free guidance.\n",
        "# сделайте это и сравните для guidance scale из множества {1, 2, 4, 32}\n",
        "# (генерации можно визуализировать в разных ячейках)\n",
        "...\n",
        "# ===="
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}