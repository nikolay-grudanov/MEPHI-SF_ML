{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89ed833",
   "metadata": {},
   "source": [
    "# –ò—Ç–æ–≥–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç: —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –≥–∏–±—Ä–∏–¥–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∫–Ω–∏–≥ —Å –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ea0779",
   "metadata": {},
   "source": [
    "**–í—ã–ø–æ–ª–Ω–∏–ª:** –ì—Ä—É–¥–∞–Ω–æ–≤ –ù–∏–∫–æ–ª–∞–π –ê–ª–µ–∫—Å–µ–µ–≤–∏—á\n",
    "**–°—Ç—É–¥–Ω—Ç –≥—Ä—É–ø–ø—ã:** –ú24-525"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27596c58",
   "metadata": {},
   "source": [
    "## –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d826ef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from surprise import Dataset, Reader, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split as surprise_train_test_split\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import torch\n",
    "import torch.cuda.memory as memory\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e172df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = (PROJECT_ROOT / \"data\" / \"goodbooks-10k\").resolve()\n",
    "print(f\"–¢–µ–∫—É—â–∞—è —Ä–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {PROJECT_ROOT}\")\n",
    "print(f\"–û–∂–∏–¥–∞–µ–º–∞—è –ª–æ–∫–∞–ª—å–Ω–∞—è –ø–∞–ø–∫–∞ —Å –¥–∞–Ω–Ω—ã–º–∏: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc49fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –Ω–∞–ª–∏—á–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ Goodbooks-10k\n",
    "REQUIRED_FILES = [\"ratings.csv\", \"books.csv\", \"tags.csv\", \"book_tags.csv\"]\n",
    "\n",
    "missing_files = [fname for fname in REQUIRED_FILES if not (DATA_DIR / fname).exists()]\n",
    "if missing_files:\n",
    "    raise FileNotFoundError(\n",
    "        \"–ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã –¥–∞—Ç–∞—Å–µ—Ç–∞: \" + \", \".join(missing_files) + f\". –û–∂–∏–¥–∞–µ–º –ø—É—Ç—å {DATA_DIR}\"\n",
    "    )\n",
    "else:\n",
    "    for fname in REQUIRED_FILES:\n",
    "        file_path = DATA_DIR / fname\n",
    "        size_mb = file_path.stat().st_size / (1024 ** 2)\n",
    "        print(f\"–§–∞–π–ª {fname} –Ω–∞–π–¥–µ–Ω ({size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8fc562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gpu_environment() -> tuple[str, torch.device, bool]:\n",
    "    \"\"\"\n",
    "    –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU –æ–∫—Ä—É–∂–µ–Ω–∏—è —Å –∫—Ä–∞—Å–∏–≤—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≤—ã–≤–æ–¥–æ–º.\n",
    "    \n",
    "    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ CUDA/ROCm,\n",
    "    –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –∏ –≤—ã–≤–æ–¥–∞ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ GPU.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (device_str: str, device: torch.device, is_gpu_available: bool)\n",
    "            - device_str: —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ ('cuda' –∏–ª–∏ 'cpu')\n",
    "            - device: –æ–±—ä–µ–∫—Ç torch.device –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –∫–æ–¥–µ\n",
    "            - is_gpu_available: —Ñ–ª–∞–≥ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU (True/False)\n",
    "    \"\"\"\n",
    "    # –ò–º–ø–æ—Ä—Ç—ã (—Ñ—É–Ω–∫—Ü–∏—è —Å–∞–º–æ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞)\n",
    "    import torch\n",
    "    import torch.cuda.memory as memory\n",
    "    \n",
    "    # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –∑–∞–≥–æ–ª–æ–≤–∫–∞\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üîç –ü–†–û–í–ï–†–ö–ê GPU –û–ö–†–£–ñ–ï–ù–ò–Ø\".center(70))\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ PyTorch\n",
    "    print(f\"\\nüì¶ PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}\")\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ CUDA/ROCm\n",
    "    is_gpu_available = torch.cuda.is_available()\n",
    "    \n",
    "    if is_gpu_available:\n",
    "        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ GPU (CUDA –∏–ª–∏ ROCm)\n",
    "        if torch.version.hip:\n",
    "            gpu_type = \"ROCm (AMD)\"\n",
    "            gpu_version = torch.version.hip\n",
    "            print(f\"‚úÖ {gpu_type} –æ–±–Ω–∞—Ä—É–∂–µ–Ω (–≤–µ—Ä—Å–∏—è: {gpu_version})\")\n",
    "        else:\n",
    "            gpu_type = \"CUDA (NVIDIA)\"\n",
    "            gpu_version = torch.version.cuda\n",
    "            print(f\"‚úÖ {gpu_type} –æ–±–Ω–∞—Ä—É–∂–µ–Ω (–≤–µ—Ä—Å–∏—è: {gpu_version})\")\n",
    "        \n",
    "        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU\n",
    "        device_count = torch.cuda.device_count()\n",
    "        print(f\"\\nüìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU:\")\n",
    "        print(f\"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU: {device_count}\")\n",
    "        \n",
    "        # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –∫–∞–∂–¥–æ–º—É GPU\n",
    "        for i in range(device_count):\n",
    "            print(f\"\\n   GPU {i}:\")\n",
    "            print(f\"   ‚Ä¢ –ò–º—è: {torch.cuda.get_device_name(i)}\")\n",
    "            total_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
    "            print(f\"   ‚Ä¢ –û–±—ä—ë–º VRAM: {total_memory:.2f} GB\")\n",
    "            print(f\"   ‚Ä¢ –í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ –±–ª–æ–∫–∏: {torch.cuda.get_device_properties(i).multi_processor_count}\")\n",
    "        \n",
    "        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞\n",
    "        device_str = 'cuda'\n",
    "        device = torch.device('cuda')\n",
    "        \n",
    "        # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\"üéØ –£–°–¢–†–û–ô–°–¢–í–û: {device}\".center(70))\n",
    "        print(f\"üìå –¢–ò–ü: {device_str}\".center(70))\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "        \n",
    "    else:\n",
    "        # GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\n",
    "        print(f\"‚ö†Ô∏è CUDA/ROCm –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\")\n",
    "        print(f\"üí° –í—ã—á–∏—Å–ª–µ–Ω–∏—è –±—É–¥—É—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –Ω–∞ CPU\")\n",
    "        \n",
    "        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞\n",
    "        device_str = 'cpu'\n",
    "        device = torch.device('cpu')\n",
    "        \n",
    "        # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\"üéØ –£–°–¢–†–û–ô–°–¢–í–û: {device}\".center(70))\n",
    "        print(f\"üìå –¢–ò–ü: {device_str}\".center(70))\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return device_str, device, is_gpu_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34777ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:\n",
    "# device_str, device, is_gpu_available = check_gpu_environment()\n",
    "# if is_gpu_available:\n",
    "#     model = model.to(device)\n",
    "# else:\n",
    "#     print(\"–ò—Å–ø–æ–ª—å–∑—É–µ–º CPU –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rocm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
